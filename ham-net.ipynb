{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-20T00:51:53.772893Z",
     "iopub.status.busy": "2025-08-20T00:51:53.771325Z",
     "iopub.status.idle": "2025-08-20T00:53:10.895786Z",
     "shell.execute_reply": "2025-08-20T00:53:10.894971Z",
     "shell.execute_reply.started": "2025-08-20T00:51:53.772868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_ema\n",
      "  Downloading torch_ema-0.3-py3-none-any.whl.metadata (415 bytes)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch_ema) (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torch_ema)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torch_ema)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torch_ema)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torch_ema)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torch_ema)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torch_ema)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torch_ema)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torch_ema)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torch_ema)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torch_ema)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch_ema) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch_ema) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch_ema) (3.0.2)\n",
      "Downloading torch_ema-0.3-py3-none-any.whl (5.5 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch_ema\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch_ema-0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:53:10.898300Z",
     "iopub.status.busy": "2025-08-20T00:53:10.897896Z",
     "iopub.status.idle": "2025-08-20T00:53:19.211169Z",
     "shell.execute_reply": "2025-08-20T00:53:19.210628Z",
     "shell.execute_reply.started": "2025-08-20T00:53:10.898275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Sequence, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from collections import defaultdict, Counter\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:53:19.212340Z",
     "iopub.status.busy": "2025-08-20T00:53:19.211995Z",
     "iopub.status.idle": "2025-08-20T00:53:19.216473Z",
     "shell.execute_reply": "2025-08-20T00:53:19.215660Z",
     "shell.execute_reply.started": "2025-08-20T00:53:19.212320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_dir = Path(\"/kaggle/input/\")\n",
    "ham_dir = base_dir / \"ham10000\" / \"ISIC-images\"\n",
    "bcn_dir = base_dir / \"bcn20000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:53:19.217656Z",
     "iopub.status.busy": "2025-08-20T00:53:19.217353Z",
     "iopub.status.idle": "2025-08-20T00:53:19.334918Z",
     "shell.execute_reply": "2025-08-20T00:53:19.334306Z",
     "shell.execute_reply.started": "2025-08-20T00:53:19.217609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:53:19.336156Z",
     "iopub.status.busy": "2025-08-20T00:53:19.335900Z",
     "iopub.status.idle": "2025-08-20T00:53:19.343518Z",
     "shell.execute_reply": "2025-08-20T00:53:19.342892Z",
     "shell.execute_reply.started": "2025-08-20T00:53:19.336137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class HAMImage:\n",
    "    path: Path\n",
    "    identifier: str\n",
    "    age: str\n",
    "    sex: str\n",
    "    diagnosis: str\n",
    "    anatom_site: str\n",
    "\n",
    "SEX_MAPPING = {\n",
    "    \"male\": 0,\n",
    "    \"female\": 1\n",
    "}\n",
    "\n",
    "DIAGNOSIS_MAPPING = {\n",
    "    \"Nevus\": 0,\n",
    "    \"Melanoma, NOS\": 1,\n",
    "    \"Pigmented benign keratosis\": 2,\n",
    "    \"Dermatofibroma\": 3,\n",
    "    \"Squamous cell carcinoma, NOS\": 4,\n",
    "    \"Basal cell carcinoma\": 5,\n",
    "    \"Solar or actinic keratosis\": 6,\n",
    "}\n",
    "\n",
    "ANATOM_SITE_MAPPING = {\n",
    "    \"anterior torso\": 0,\n",
    "    \"posterior torso\": 1,\n",
    "    \"head/neck\": 2,\n",
    "    \"upper extremity\": 3,\n",
    "    \"lower extremity\": 4,\n",
    "    \"palms/soles\": 5,\n",
    "    \"oral/genital\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:53:19.344484Z",
     "iopub.status.busy": "2025-08-20T00:53:19.344189Z",
     "iopub.status.idle": "2025-08-20T00:53:19.358483Z",
     "shell.execute_reply": "2025-08-20T00:53:19.357912Z",
     "shell.execute_reply.started": "2025-08-20T00:53:19.344460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def concat_metadata(paths: List[Path]) -> pd.DataFrame:\n",
    "    data = pd.DataFrame()\n",
    "    for path in paths:\n",
    "        metadata = pd.read_csv(path / \"metadata.csv\")\n",
    "        metadata[\"base_path\"] = path.as_posix()\n",
    "        data = pd.concat([data, metadata])\n",
    "    data = data.drop_duplicates([\"isic_id\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:53:19.361145Z",
     "iopub.status.busy": "2025-08-20T00:53:19.360974Z",
     "iopub.status.idle": "2025-08-20T00:53:19.374199Z",
     "shell.execute_reply": "2025-08-20T00:53:19.373550Z",
     "shell.execute_reply.started": "2025-08-20T00:53:19.361131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_metadata(metadata: pd.DataFrame) -> List[HAMImage]:\n",
    "    metadata = metadata[pd.notnull(metadata[\"age_approx\"])]\n",
    "    metadata = metadata[pd.notnull(metadata[\"sex\"])]\n",
    "    metadata = metadata[pd.notnull(metadata[\"anatom_site_general\"])]\n",
    "    metadata = metadata[pd.notnull(metadata[\"diagnosis_3\"])]\n",
    "    images: List[HAMImage] = []\n",
    "    for idx, row in metadata.iterrows():\n",
    "        images.append(\n",
    "            HAMImage(\n",
    "                path=Path(row[\"base_path\"]),\n",
    "                identifier=row[\"isic_id\"],\n",
    "                age=row[\"age_approx\"],\n",
    "                sex=row[\"sex\"],\n",
    "                diagnosis=row[\"diagnosis_3\"],\n",
    "                anatom_site=row[\"anatom_site_general\"]\n",
    "            )\n",
    "        )\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:53:19.375331Z",
     "iopub.status.busy": "2025-08-20T00:53:19.374922Z",
     "iopub.status.idle": "2025-08-20T00:53:19.393153Z",
     "shell.execute_reply": "2025-08-20T00:53:19.392575Z",
     "shell.execute_reply.started": "2025-08-20T00:53:19.375308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def print_diagnosis_counts_by_sex(images: List[HAMImage]) -> None:\n",
    "    counts_by_sex: dict[int, Counter[int]] = defaultdict(Counter)\n",
    "    for img in images:\n",
    "        counts_by_sex[img.sex][img.diagnosis] += 1\n",
    "\n",
    "    all_diagnoses = sorted({d for ctr in counts_by_sex.values() for d in ctr})\n",
    "    all_sexes = sorted(counts_by_sex)\n",
    "\n",
    "    diag_col = \"Diagnosis\"\n",
    "    sex_cols = [f\"Sex {s}\" for s in all_sexes]\n",
    "\n",
    "    w_diag = max(len(diag_col), *(len(str(d)) for d in all_diagnoses))\n",
    "    w_sex = {\n",
    "        s: max(len(f\"Sex {s}\"), *(len(str(counts_by_sex[s][d])) for d in all_diagnoses))\n",
    "        for s in all_sexes\n",
    "    }\n",
    "\n",
    "    header = f\"{diag_col:<{w_diag}} \" + \" \".join(\n",
    "        f\"| {name:>{w_sex[s]}}\" for s, name in zip(all_sexes, sex_cols)\n",
    "    )\n",
    "    sep = \"-\" * len(header)\n",
    "    print(header)\n",
    "    print(sep)\n",
    "\n",
    "    for d in all_diagnoses:\n",
    "        row = f\"{str(d):<{w_diag}} \" + \" \".join(\n",
    "            f\"| {counts_by_sex[s][d]:>{w_sex[s]}}\" for s in all_sexes\n",
    "        )\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:53:19.394025Z",
     "iopub.status.busy": "2025-08-20T00:53:19.393788Z",
     "iopub.status.idle": "2025-08-20T00:53:19.408601Z",
     "shell.execute_reply": "2025-08-20T00:53:19.407893Z",
     "shell.execute_reply.started": "2025-08-20T00:53:19.394001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_mean_std(values: List[Any]) -> Tuple[float, float]:\n",
    "    arr = np.array(values, dtype=np.float32)\n",
    "    return float(arr.mean()), float(arr.std())\n",
    "\n",
    "def normalize_meta(values: Sequence[float], means: Sequence[float], stds: Sequence[float]) -> torch.Tensor:\n",
    "    normed = [(v - m) / s for v, m, s in zip(values, means, stds)]\n",
    "    return torch.tensor(normed, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:52:57.093165Z",
     "iopub.status.busy": "2025-08-20T03:52:57.092860Z",
     "iopub.status.idle": "2025-08-20T03:52:57.103113Z",
     "shell.execute_reply": "2025-08-20T03:52:57.102309Z",
     "shell.execute_reply.started": "2025-08-20T03:52:57.093136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HAMDiagnosisDataset(Dataset):\n",
    "    def __init__(self, images: List[HAMImage], train: bool) -> None:\n",
    "        self.images = images\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "        ages = [img.age for img in images]\n",
    "        self.mean_age, self.std_age = compute_mean_std(ages)\n",
    "        \n",
    "        sexes = [SEX_MAPPING[img.sex] for img in images]\n",
    "        self.mean_sex, self.std_sex = compute_mean_std(sexes)\n",
    "\n",
    "        sites = [ANATOM_SITE_MAPPING[img.anatom_site] for img in images]\n",
    "        self.mean_site, self.std_site = compute_mean_std(sites)\n",
    "\n",
    "        if not train:\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((500, 500)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.mean, self.std),\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((500, 500)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.mean, self.std)\n",
    "            ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        image = self.images[index]\n",
    "        image_path = image.path / f\"{image.identifier}.jpg\"\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transforms(img)\n",
    "\n",
    "        sex = SEX_MAPPING[image.sex]\n",
    "        diagnosis = DIAGNOSIS_MAPPING[image.diagnosis]\n",
    "        site = ANATOM_SITE_MAPPING[image.anatom_site]\n",
    "        age = float(image.age)\n",
    "    \n",
    "        meta = normalize_meta(\n",
    "            values=[sex, age, site],\n",
    "            means=[self.mean_sex, self.mean_age, self.mean_site],\n",
    "            stds=[self.std_sex, self.std_age, self.std_site]\n",
    "        )\n",
    "        return img, meta, diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:52:58.193036Z",
     "iopub.status.busy": "2025-08-20T03:52:58.192283Z",
     "iopub.status.idle": "2025-08-20T03:52:58.789233Z",
     "shell.execute_reply": "2025-08-20T03:52:58.788614Z",
     "shell.execute_reply.started": "2025-08-20T03:52:58.193003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis                    | Sex female | Sex male\n",
      "----------------------------------------------------\n",
      "Basal cell carcinoma         |        209 |      362\n",
      "Dermatofibroma               |         63 |       66\n",
      "Melanoma, NOS                |        475 |      741\n",
      "Nevus                        |       2929 |     3021\n",
      "Pigmented benign keratosis   |        486 |      655\n",
      "Solar or actinic keratosis   |         46 |       99\n",
      "Squamous cell carcinoma, NOS |         79 |      150\n"
     ]
    }
   ],
   "source": [
    "metadata = concat_metadata(paths=[ham_dir])\n",
    "images = load_metadata(metadata=metadata)\n",
    "print_diagnosis_counts_by_sex(images=images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:52:59.258671Z",
     "iopub.status.busy": "2025-08-20T03:52:59.258440Z",
     "iopub.status.idle": "2025-08-20T03:52:59.275755Z",
     "shell.execute_reply": "2025-08-20T03:52:59.275203Z",
     "shell.execute_reply.started": "2025-08-20T03:52:59.258653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "\n",
    "labels = [DIAGNOSIS_MAPPING[img.diagnosis] for img in images]\n",
    "\n",
    "train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, stratify=labels, random_state=SEED\n",
    ")\n",
    "\n",
    "val_images, test_images, _, _ = train_test_split(\n",
    "    temp_images, temp_labels, test_size=0.5, stratify=temp_labels, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:52:59.420468Z",
     "iopub.status.busy": "2025-08-20T03:52:59.420191Z",
     "iopub.status.idle": "2025-08-20T03:52:59.438931Z",
     "shell.execute_reply": "2025-08-20T03:52:59.438081Z",
     "shell.execute_reply.started": "2025-08-20T03:52:59.420449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = HAMDiagnosisDataset(train_images, train=True)\n",
    "test = HAMDiagnosisDataset(test_images, train=False)\n",
    "val = HAMDiagnosisDataset(val_images, train=False)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "trainloader = DataLoader(train, shuffle=True, batch_size=64, generator=g, num_workers=6)\n",
    "testloader = DataLoader(test, shuffle=False, batch_size=32, num_workers=2)\n",
    "valloader = DataLoader(val, shuffle=False, batch_size=32, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:53:00.390575Z",
     "iopub.status.busy": "2025-08-20T03:53:00.390258Z",
     "iopub.status.idle": "2025-08-20T03:53:00.855429Z",
     "shell.execute_reply": "2025-08-20T03:53:00.854550Z",
     "shell.execute_reply.started": "2025-08-20T03:53:00.390554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet50_Weights\n",
    "resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:53:00.856873Z",
     "iopub.status.busy": "2025-08-20T03:53:00.856635Z",
     "iopub.status.idle": "2025-08-20T03:53:00.862182Z",
     "shell.execute_reply": "2025-08-20T03:53:00.861480Z",
     "shell.execute_reply.started": "2025-08-20T03:53:00.856849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for name, param in resnet.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, module in resnet.named_modules():\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:53:01.289729Z",
     "iopub.status.busy": "2025-08-20T03:53:01.289488Z",
     "iopub.status.idle": "2025-08-20T03:53:01.315961Z",
     "shell.execute_reply": "2025-08-20T03:53:01.315141Z",
     "shell.execute_reply.started": "2025-08-20T03:53:01.289714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_features = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Identity()\n",
    "\n",
    "meta_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 16),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Linear(16, 8),\n",
    "    torch.nn.SiLU()\n",
    ")\n",
    "\n",
    "classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(num_features + 8, 1024),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(1024, 7)\n",
    ")\n",
    "\n",
    "class HAMNet(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet = resnet\n",
    "        self.meta_net = meta_net\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, img: torch.Tensor, meta: torch.Tensor) -> torch.Tensor:\n",
    "        img_features = self.resnet(img)\n",
    "        meta_features = self.meta_net(meta)\n",
    "        x = torch.cat([img_features, meta_features], dim=1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:53:02.824151Z",
     "iopub.status.busy": "2025-08-20T03:53:02.823868Z",
     "iopub.status.idle": "2025-08-20T03:53:02.831134Z",
     "shell.execute_reply": "2025-08-20T03:53:02.830187Z",
     "shell.execute_reply.started": "2025-08-20T03:53:02.824126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import ResNet\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "def evaluate(\n",
    "    model: ResNet,\n",
    "    loader: DataLoader,\n",
    "    criterion: CrossEntropyLoss,\n",
    "    ema: ExponentialMovingAverage,\n",
    ") -> Tuple[int, int, List[np.ndarray], List[np.ndarray]]:\n",
    "    model.eval()\n",
    "    ema.store()\n",
    "    ema.copy_to()\n",
    "    correct = total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (imgs, meta, labels) in tqdm(loader, desc=f\"Evaluation: \"):\n",
    "            imgs, meta, labels = imgs.to(device), meta.to(device), labels.to(device)\n",
    "\n",
    "            logits = model(imgs, meta)\n",
    "            loss = criterion(logits, labels)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    ema.restore()\n",
    "    eval_loss = running_loss / len(loader.dataset)\n",
    "    return eval_loss, correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:53:03.788612Z",
     "iopub.status.busy": "2025-08-20T03:53:03.788362Z",
     "iopub.status.idle": "2025-08-20T03:53:03.795218Z",
     "shell.execute_reply": "2025-08-20T03:53:03.794665Z",
     "shell.execute_reply.started": "2025-08-20T03:53:03.788592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter(train_labels)\n",
    "num_classes = len(list(set(train_labels)))\n",
    "\n",
    "counts = torch.bincount(torch.tensor(train_labels), minlength=num_classes)\n",
    "weights = counts.sum() / (num_classes * counts.clamp_min(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:53:03.924717Z",
     "iopub.status.busy": "2025-08-20T03:53:03.924224Z",
     "iopub.status.idle": "2025-08-20T03:53:03.928939Z",
     "shell.execute_reply": "2025-08-20T03:53:03.928191Z",
     "shell.execute_reply.started": "2025-08-20T03:53:03.924700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def unfreeze_layer(model: ResNet, layer: str) -> None:\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(layer):\n",
    "            param.requires_grad = True\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if name.startswith(layer) and isinstance(module, torch.nn.BatchNorm2d):\n",
    "            module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:53:04.918135Z",
     "iopub.status.busy": "2025-08-20T03:53:04.917451Z",
     "iopub.status.idle": "2025-08-20T03:53:04.926148Z",
     "shell.execute_reply": "2025-08-20T03:53:04.925380Z",
     "shell.execute_reply.started": "2025-08-20T03:53:04.918113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from torch.optim import SGD\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ParamGroup:\n",
    "    layer: str\n",
    "    epoch: int\n",
    "    params: torch.nn.Parameter\n",
    "    lr: float\n",
    "    momentum: float\n",
    "    decay: float\n",
    "\n",
    "    @property\n",
    "    def group(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"params\": self.params,\n",
    "            \"lr\": self.lr,\n",
    "            \"momentum\": self.momentum,\n",
    "            \"weight_decay\": self.decay\n",
    "        }\n",
    "\n",
    "\n",
    "class ProgressiveUnfreezer:\n",
    "    def __init__(self, model: ResNet, optimizer: SGD, params: List[ParamGroup]) -> None:\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.params = deque(sorted(params, key=lambda x: x.epoch))\n",
    "    \n",
    "    def unfreeze(self, epoch: int) -> None:\n",
    "        if not len(self.params):\n",
    "            return None\n",
    "\n",
    "        top = self.params[0]\n",
    "        if epoch == top.epoch:\n",
    "            unfreeze_layer(model=self.model, layer=top.layer)\n",
    "            self.optimizer.add_param_group(top.group)\n",
    "            self.params.popleft()\n",
    "            print(\"Unfreezing layer...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T03:53:06.114112Z",
     "iopub.status.busy": "2025-08-20T03:53:06.113543Z",
     "iopub.status.idle": "2025-08-20T05:38:04.484768Z",
     "shell.execute_reply": "2025-08-20T05:38:04.483846Z",
     "shell.execute_reply.started": "2025-08-20T03:53:06.114092Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 118/118 [01:37<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100.. Train loss: 2.280.. Val loss: 2.283.. Accuracy: 0.017..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 118/118 [01:37<00:00,  1.22it/s]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100.. Train loss: 2.276.. Val loss: 2.271.. Accuracy: 0.017..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 118/118 [01:37<00:00,  1.22it/s]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100.. Train loss: 2.247.. Val loss: 2.259.. Accuracy: 0.021..\n",
      "Unfreezing layer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 118/118 [01:41<00:00,  1.16it/s]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100.. Train loss: 2.207.. Val loss: 2.221.. Accuracy: 0.030..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 118/118 [01:42<00:00,  1.15it/s]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100.. Train loss: 2.103.. Val loss: 2.149.. Accuracy: 0.110..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 118/118 [01:42<00:00,  1.16it/s]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100.. Train loss: 2.016.. Val loss: 2.052.. Accuracy: 0.376..\n",
      "Unfreezing layer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100.. Train loss: 1.867.. Val loss: 1.916.. Accuracy: 0.515..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100.. Train loss: 1.688.. Val loss: 1.751.. Accuracy: 0.604..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100.. Train loss: 1.533.. Val loss: 1.633.. Accuracy: 0.620..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100.. Train loss: 1.446.. Val loss: 1.588.. Accuracy: 0.659..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:17<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100.. Train loss: 1.369.. Val loss: 1.518.. Accuracy: 0.680..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100.. Train loss: 1.294.. Val loss: 1.507.. Accuracy: 0.678..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100.. Train loss: 1.233.. Val loss: 1.571.. Accuracy: 0.682..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100.. Train loss: 1.220.. Val loss: 1.452.. Accuracy: 0.694..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100.. Train loss: 1.141.. Val loss: 1.491.. Accuracy: 0.701..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100.. Train loss: 1.118.. Val loss: 1.439.. Accuracy: 0.717..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100.. Train loss: 1.053.. Val loss: 1.377.. Accuracy: 0.759..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100.. Train loss: 1.024.. Val loss: 1.393.. Accuracy: 0.773..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100.. Train loss: 1.012.. Val loss: 1.394.. Accuracy: 0.775..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100.. Train loss: 0.997.. Val loss: 1.389.. Accuracy: 0.773..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:17<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100.. Train loss: 0.987.. Val loss: 1.399.. Accuracy: 0.795..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:17<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100.. Train loss: 0.945.. Val loss: 1.404.. Accuracy: 0.758..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100.. Train loss: 0.930.. Val loss: 1.411.. Accuracy: 0.788..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100.. Train loss: 0.912.. Val loss: 1.366.. Accuracy: 0.774..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100.. Train loss: 0.905.. Val loss: 1.375.. Accuracy: 0.812..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100.. Train loss: 0.895.. Val loss: 1.363.. Accuracy: 0.827..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 118/118 [02:05<00:00,  1.07s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100.. Train loss: 0.869.. Val loss: 1.366.. Accuracy: 0.803..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100.. Train loss: 0.882.. Val loss: 1.334.. Accuracy: 0.834..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100.. Train loss: 0.862.. Val loss: 1.345.. Accuracy: 0.814..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100.. Train loss: 0.868.. Val loss: 1.338.. Accuracy: 0.823..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:17<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100.. Train loss: 0.864.. Val loss: 1.321.. Accuracy: 0.849..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100.. Train loss: 0.856.. Val loss: 1.346.. Accuracy: 0.832..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100.. Train loss: 0.841.. Val loss: 1.341.. Accuracy: 0.853..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100.. Train loss: 0.839.. Val loss: 1.353.. Accuracy: 0.850..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100.. Train loss: 0.839.. Val loss: 1.323.. Accuracy: 0.845..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100.. Train loss: 0.835.. Val loss: 1.337.. Accuracy: 0.852..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100.. Train loss: 0.839.. Val loss: 1.357.. Accuracy: 0.846..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100.. Train loss: 0.833.. Val loss: 1.319.. Accuracy: 0.841..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100.. Train loss: 0.818.. Val loss: 1.352.. Accuracy: 0.859..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100.. Train loss: 0.824.. Val loss: 1.321.. Accuracy: 0.855..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100.. Train loss: 0.824.. Val loss: 1.340.. Accuracy: 0.852..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 118/118 [02:04<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100.. Train loss: 0.812.. Val loss: 1.343.. Accuracy: 0.862..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100.. Train loss: 0.818.. Val loss: 1.328.. Accuracy: 0.856..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100.. Train loss: 0.812.. Val loss: 1.357.. Accuracy: 0.867..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 118/118 [02:05<00:00,  1.06s/it]\n",
      "Evaluation: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100.. Train loss: 0.812.. Val loss: 1.356.. Accuracy: 0.866..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "model = HAMNet()\n",
    "model.to(device)\n",
    "\n",
    "ema = ExponentialMovingAverage(model.parameters(), decay=0.999)\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "unfreeze_layer(model=model.resnet, layer=\"fc\")\n",
    "optimizer = SGD([{\"params\": model.classifier.parameters(), \"lr\": 1e-3, \"momentum\": 0.9, \"weight_decay\": 1e-3}])\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "criterion = CrossEntropyLoss(label_smoothing=0.05, weight=torch.tensor(weights).to(device))\n",
    "\n",
    "patience = 7\n",
    "best_loss = float(\"inf\")\n",
    "no_improve = 0\n",
    "\n",
    "scaler = GradScaler()\n",
    "unfreezer = ProgressiveUnfreezer(\n",
    "    model.resnet, \n",
    "    optimizer,\n",
    "    [\n",
    "        ParamGroup(\n",
    "            layer=\"layer4\", \n",
    "            epoch=3, \n",
    "            params=model.resnet.layer4.parameters(), \n",
    "            lr=5e-3,\n",
    "            momentum=0.9,\n",
    "            decay=1e-5\n",
    "        ),\n",
    "        ParamGroup(\n",
    "            layer=\"layer3\",\n",
    "            epoch=6,\n",
    "            params=model.resnet.layer3.parameters(),\n",
    "            lr=3e-3,\n",
    "            momentum=0.9,\n",
    "            decay=1e-5\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for imgs, meta, labels in tqdm(trainloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        imgs, meta, labels = imgs.to(device), meta.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            preds = model(imgs, meta)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        ema.update()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(trainloader.dataset)\n",
    "\n",
    "    scheduler.step()\n",
    "    val_loss, val_acc, _, _ = evaluate(model, valloader, criterion, ema)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}.. \"\n",
    "          f\"Train loss: {train_loss:.3f}.. \"\n",
    "          f\"Val loss: {val_loss:.3f}.. \"\n",
    "          f\"Accuracy: {val_acc:.3f}..\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        no_improve = 0\n",
    "        best_loss = val_loss\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            break\n",
    "\n",
    "    unfreezer.unfreeze(epoch=epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T05:38:12.269342Z",
     "iopub.status.busy": "2025-08-20T05:38:12.269028Z",
     "iopub.status.idle": "2025-08-20T05:38:30.293075Z",
     "shell.execute_reply": "2025-08-20T05:38:30.292270Z",
     "shell.execute_reply.started": "2025-08-20T05:38:12.269315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 30/30 [00:17<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.317.. Test Accuracy: 0.853..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, _, _ = evaluate(model, testloader, criterion, ema)\n",
    "print(f\"Test Loss: {test_loss:.3f}.. \"\n",
    "      f\"Test Accuracy: {test_acc:.3f}..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T05:38:45.929532Z",
     "iopub.status.busy": "2025-08-20T05:38:45.929157Z",
     "iopub.status.idle": "2025-08-20T05:38:46.224761Z",
     "shell.execute_reply": "2025-08-20T05:38:46.223979Z",
     "shell.execute_reply.started": "2025-08-20T05:38:45.929502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"ham-net.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
